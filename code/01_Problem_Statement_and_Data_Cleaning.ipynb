{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0ebbdc",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d3167",
   "metadata": {},
   "source": [
    "## Problem Statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f41c3f",
   "metadata": {},
   "source": [
    "The Housing & Development Board (HDB) flats are a type of public housing in Singapore. They are highly sought after by both Singaporean citizens and permanent residents due to their affordability and various amenities provided by the government.\n",
    "Real estate agents play a crucial role in facilitating the buying and selling of properties, including HDB flats. Their expertise and knowledge of the local market are essential in helping clients make informed decisions and achieve the best possible outcomes. To effectively serve their clients and maximize their business potential, real estate agents need accurate and reliable price predictions for HDB flats.\n",
    "To address this need, our team of data scientists has been engaged by a group of real estate agents who are planning to establish their own real estate agency. They have specifically identified HDB flats as their primary focus and want us to develop a price prediction model tailored to this housing type. The aim of our data science project is to create a robust and accurate price prediction model for HDB flats. The successful implementation of this price prediction model will enable the real estate agents to make data-driven decisions, offer competitive pricing recommendations, attract more clients, and establish themselves as trusted advisors in the HDB market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcdb11",
   "metadata": {},
   "source": [
    "## Aim of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74940bbe",
   "metadata": {},
   "source": [
    "- To create a working linear regression model to predict HDB prices\n",
    "- To understand what are the key predictors of HDB prices\n",
    "- Success of the model will be evaluated by its R-squared and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975dc2a2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e81b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59faf5",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6b5d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/61_m3nz133bcpt1gp9t0vyq00000gn/T/ipykernel_1000/1963004826.py:1: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  housing_train = pd.read_csv('../datasets/train.csv')\n",
      "/var/folders/r4/61_m3nz133bcpt1gp9t0vyq00000gn/T/ipykernel_1000/1963004826.py:2: DtypeWarning: Columns (41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  housing_test = pd.read_csv('../datasets/test.csv')\n"
     ]
    }
   ],
   "source": [
    "housing_train = pd.read_csv('../datasets/train.csv')\n",
    "housing_test = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246a00cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>Tranc_Year</th>\n",
       "      <th>Tranc_Month</th>\n",
       "      <th>mid_storey</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mid</th>\n",
       "      <th>...</th>\n",
       "      <th>pri_sch_nearest_distance</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>pri_sch_affiliation</th>\n",
       "      <th>pri_sch_latitude</th>\n",
       "      <th>pri_sch_longitude</th>\n",
       "      <th>sec_sch_nearest_dist</th>\n",
       "      <th>cutoff_point</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>sec_sch_latitude</th>\n",
       "      <th>sec_sch_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.00000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>1.506340e+05</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "      <td>150634.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93047.887496</td>\n",
       "      <td>97.19763</td>\n",
       "      <td>1992.448464</td>\n",
       "      <td>4.491615e+05</td>\n",
       "      <td>2016.489551</td>\n",
       "      <td>6.580500</td>\n",
       "      <td>8.284823</td>\n",
       "      <td>7.248370</td>\n",
       "      <td>9.321275</td>\n",
       "      <td>8.284823</td>\n",
       "      <td>...</td>\n",
       "      <td>395.172974</td>\n",
       "      <td>55.368190</td>\n",
       "      <td>0.113195</td>\n",
       "      <td>1.366268</td>\n",
       "      <td>103.839106</td>\n",
       "      <td>508.533220</td>\n",
       "      <td>210.146428</td>\n",
       "      <td>0.031879</td>\n",
       "      <td>1.365986</td>\n",
       "      <td>103.839340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>53679.906247</td>\n",
       "      <td>24.40304</td>\n",
       "      <td>12.138829</td>\n",
       "      <td>1.433076e+05</td>\n",
       "      <td>2.752396</td>\n",
       "      <td>3.345468</td>\n",
       "      <td>5.508074</td>\n",
       "      <td>5.515155</td>\n",
       "      <td>5.507364</td>\n",
       "      <td>5.508074</td>\n",
       "      <td>...</td>\n",
       "      <td>234.760931</td>\n",
       "      <td>17.903918</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.042669</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>309.066265</td>\n",
       "      <td>20.010489</td>\n",
       "      <td>0.175677</td>\n",
       "      <td>0.042599</td>\n",
       "      <td>0.072630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.668324</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.274962</td>\n",
       "      <td>103.687724</td>\n",
       "      <td>38.913475</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.276029</td>\n",
       "      <td>103.687207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46469.250000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>3.470000e+05</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>227.083163</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.337289</td>\n",
       "      <td>103.773754</td>\n",
       "      <td>290.285883</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.337545</td>\n",
       "      <td>103.776008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>93077.500000</td>\n",
       "      <td>95.00000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>4.200000e+05</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>348.876691</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.364639</td>\n",
       "      <td>103.844210</td>\n",
       "      <td>447.377670</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366132</td>\n",
       "      <td>103.842719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139574.750000</td>\n",
       "      <td>112.00000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>5.200000e+05</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>502.179385</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.393910</td>\n",
       "      <td>103.898773</td>\n",
       "      <td>644.284099</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.391781</td>\n",
       "      <td>103.899872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>185966.000000</td>\n",
       "      <td>280.00000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.258000e+06</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3305.841039</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.456667</td>\n",
       "      <td>103.962919</td>\n",
       "      <td>3638.977233</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.453280</td>\n",
       "      <td>103.961105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  floor_area_sqm  lease_commence_date  resale_price  \\\n",
       "count  150634.000000    150634.00000        150634.000000  1.506340e+05   \n",
       "mean    93047.887496        97.19763          1992.448464  4.491615e+05   \n",
       "std     53679.906247        24.40304            12.138829  1.433076e+05   \n",
       "min         1.000000        31.00000          1966.000000  1.500000e+05   \n",
       "25%     46469.250000        75.00000          1984.000000  3.470000e+05   \n",
       "50%     93077.500000        95.00000          1992.000000  4.200000e+05   \n",
       "75%    139574.750000       112.00000          2001.000000  5.200000e+05   \n",
       "max    185966.000000       280.00000          2019.000000  1.258000e+06   \n",
       "\n",
       "          Tranc_Year    Tranc_Month     mid_storey          lower  \\\n",
       "count  150634.000000  150634.000000  150634.000000  150634.000000   \n",
       "mean     2016.489551       6.580500       8.284823       7.248370   \n",
       "std         2.752396       3.345468       5.508074       5.515155   \n",
       "min      2012.000000       1.000000       2.000000       1.000000   \n",
       "25%      2014.000000       4.000000       5.000000       4.000000   \n",
       "50%      2017.000000       7.000000       8.000000       7.000000   \n",
       "75%      2019.000000       9.000000      11.000000      10.000000   \n",
       "max      2021.000000      12.000000      50.000000      49.000000   \n",
       "\n",
       "               upper            mid  ...  pri_sch_nearest_distance  \\\n",
       "count  150634.000000  150634.000000  ...             150634.000000   \n",
       "mean        9.321275       8.284823  ...                395.172974   \n",
       "std         5.507364       5.508074  ...                234.760931   \n",
       "min         3.000000       2.000000  ...                 45.668324   \n",
       "25%         6.000000       5.000000  ...                227.083163   \n",
       "50%         9.000000       8.000000  ...                348.876691   \n",
       "75%        12.000000      11.000000  ...                502.179385   \n",
       "max        51.000000      50.000000  ...               3305.841039   \n",
       "\n",
       "             vacancy  pri_sch_affiliation  pri_sch_latitude  \\\n",
       "count  150634.000000        150634.000000     150634.000000   \n",
       "mean       55.368190             0.113195          1.366268   \n",
       "std        17.903918             0.316832          0.042669   \n",
       "min        20.000000             0.000000          1.274962   \n",
       "25%        44.000000             0.000000          1.337289   \n",
       "50%        54.000000             0.000000          1.364639   \n",
       "75%        67.000000             0.000000          1.393910   \n",
       "max       110.000000             1.000000          1.456667   \n",
       "\n",
       "       pri_sch_longitude  sec_sch_nearest_dist   cutoff_point    affiliation  \\\n",
       "count      150634.000000         150634.000000  150634.000000  150634.000000   \n",
       "mean          103.839106            508.533220     210.146428       0.031879   \n",
       "std             0.072637            309.066265      20.010489       0.175677   \n",
       "min           103.687724             38.913475     188.000000       0.000000   \n",
       "25%           103.773754            290.285883     188.000000       0.000000   \n",
       "50%           103.844210            447.377670     208.000000       0.000000   \n",
       "75%           103.898773            644.284099     224.000000       0.000000   \n",
       "max           103.962919           3638.977233     260.000000       1.000000   \n",
       "\n",
       "       sec_sch_latitude  sec_sch_longitude  \n",
       "count     150634.000000      150634.000000  \n",
       "mean           1.365986         103.839340  \n",
       "std            0.042599           0.072630  \n",
       "min            1.276029         103.687207  \n",
       "25%            1.337545         103.776008  \n",
       "50%            1.366132         103.842719  \n",
       "75%            1.391781         103.899872  \n",
       "max            1.453280         103.961105  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cfd091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean column names\n",
    "housing_train.columns=housing_train.columns.str.lower()\n",
    "housing_test.columns=housing_test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98aaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of NaN for mall_nearest_distance: 829\n",
      "no. of NaN for mall_within_500m: 92789\n",
      "no. of NaN for mall_within_1km: 25426\n",
      "no. of NaN for mall_within_2km: 1940\n",
      "no. of NaN for hawker_within_500m: 97390\n",
      "no. of NaN for hawker_within_1km: 60868\n",
      "no. of NaN for hawker_within_2km: 29202\n",
      "\n",
      "\n",
      "no. of NaN for mall_nearest_distance: 84\n",
      "no. of NaN for mall_within_500m: 10292\n",
      "no. of NaN for mall_within_1km: 2786\n",
      "no. of NaN for mall_within_2km: 213\n",
      "no. of NaN for hawker_within_500m: 10755\n",
      "no. of NaN for hawker_within_1km: 6729\n",
      "no. of NaN for hawker_within_2km: 3254\n"
     ]
    }
   ],
   "source": [
    "# find all columns with NaN (train)\n",
    "nan_cols_train=housing_train.columns[housing_train.isna().any()].tolist()\n",
    "# find number of rows with NaN for each column in nan_cols\n",
    "for i in nan_cols_train:\n",
    "    print(f'no. of NaN for {i}: {housing_train[i].isna().sum()}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# find all columns with NaN (test)\n",
    "nan_cols_test=housing_test.columns[housing_test.isna().any()].tolist()\n",
    "for i in nan_cols_test:\n",
    "    print(f'no. of NaN for {i}: {housing_test[i].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f829dd1",
   "metadata": {},
   "source": [
    "Note here that number of NaN for malls / hawkers (within a certain radius) decreases as radius increases, which makes sense if we assume that NaN stands for 0 malls / hawkers in the specified radius."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3c534",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0211904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dups\n",
    "df_drop_dups=housing_train.drop_duplicates(subset=['longitude','latitude'])\n",
    "df_w_na_no_dups=df_drop_dups[df_drop_dups['mall_nearest_distance'].isna()]\n",
    "\n",
    "# index of rows with NaN in 'mall_nearest_distance'\n",
    "idx_w_na=list(housing_train[housing_train['mall_nearest_distance'].isna()].index.values)\n",
    "idx_w_na_no_dups=list(df_w_na_no_dups.index.values)\n",
    "len(idx_w_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41b81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows with no NaN in 'mall_nearest_distance' and no dups\n",
    "df_no_na_no_dups=df_drop_dups[df_drop_dups['mall_nearest_distance'].notna()]\n",
    "idx_no_na_no_dups=list(df_no_na_no_dups.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc720c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function 'shortest_l' that finds the row in df that has the shortest distance between the 'long_org' and 'lat_org' input,\n",
    "# and returns the 'mall_nearest_distance' for that row\n",
    "# find shortest length between 2 points\n",
    "def shortest_l(idx,df,long_org,lat_org):\n",
    "    dist=999\n",
    "    new_info=[0,0,0]\n",
    "    for i in idx:\n",
    "        new_dist=((long_org - df.loc[i]['longitude'])**2 + (lat_org - df.loc[i]['latitude'])**2)**0.5\n",
    "        if new_dist<dist:\n",
    "            dist=new_dist\n",
    "            new_info[0]=df.loc[i]['longitude']\n",
    "            new_info[1]=df.loc[i]['latitude']\n",
    "            new_info[2]=df.loc[i]['mall_nearest_distance']\n",
    "    return new_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=idx_no_na_no_dups\n",
    "df=df_no_na_no_dups\n",
    "# Looping through the housing_train dataframe to impute 'mall_nearest_distance' for rows with missing values\n",
    "for i in idx_w_na: \n",
    "    housing_train.iloc[i,46]=shortest_l(idx,df,housing_train['longitude'][i],housing_train['latitude'][i])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426dc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0 for cols with NaN\n",
    "for i in nan_cols_train:\n",
    "    housing_train[i] = housing_train[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ec5770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of NaNs</th>\n",
       "      <th>% of total rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [number of NaNs, % of total rows]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for cols with NaN\n",
    "def null_check(df):\n",
    "    is_null = df.isna().sum().sort_values()\n",
    "    is_null_df = is_null.to_frame()\n",
    "    is_null_df = is_null_df.rename({0:'number of NaNs'}, axis = 1)\n",
    "    is_null_df['% of total rows'] = is_null_df['number of NaNs']/df.shape[0]*100\n",
    "    is_null_df = is_null_df[is_null_df.loc[:]!=0].dropna()\n",
    "    return is_null_df\n",
    "\n",
    "null_check(housing_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30619c1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985561d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dups\n",
    "df_drop_dups_test=housing_test.drop_duplicates(subset=['longitude','latitude'])\n",
    "df_w_na_no_dups_test=df_drop_dups_test[df_drop_dups_test['mall_nearest_distance'].isna()]\n",
    "\n",
    "# index of rows with NaN in 'mall_nearest_distance'\n",
    "idx_w_na_test=list(housing_test[housing_test['mall_nearest_distance'].isna()].index.values)\n",
    "idx_w_na_no_dups=list(df_w_na_no_dups_test.index.values)\n",
    "len(idx_w_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "093d3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows with no NaN in 'mall_nearest_distance' and no dups\n",
    "df_no_na_no_dups_test=df_drop_dups_test[df_drop_dups_test['mall_nearest_distance'].notna()]\n",
    "idx_no_na_no_dups_test=list(df_no_na_no_dups_test.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dc3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=idx_no_na_no_dups_test\n",
    "df=df_no_na_no_dups_test\n",
    "# Looping through the housing_test dataframe to impute 'mall_nearest_distance' for rows with missing values\n",
    "for i in idx_w_na_test: \n",
    "    housing_test.iloc[i,45]=shortest_l(idx,df,housing_test['longitude'][i],housing_test['latitude'][i])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db9c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0 for cols with NaN\n",
    "for i in nan_cols_test:\n",
    "    housing_test[i] = housing_test[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a88e304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of NaNs</th>\n",
       "      <th>% of total rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [number of NaNs, % of total rows]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for cols with NaN\n",
    "def null_check(df):\n",
    "    is_null = df.isna().sum().sort_values()\n",
    "    is_null_df = is_null.to_frame()\n",
    "    is_null_df = is_null_df.rename({0:'number of NaNs'}, axis = 1)\n",
    "    is_null_df['% of total rows'] = is_null_df['number of NaNs']/df.shape[0]*100\n",
    "    is_null_df = is_null_df[is_null_df.loc[:]!=0].dropna()\n",
    "    return is_null_df\n",
    "\n",
    "null_check(housing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2382841",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5c226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.to_csv('../datasets/train_pop_NaN.csv',index=False)\n",
    "housing_test.to_csv('../datasets/test_pop_NaN.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
